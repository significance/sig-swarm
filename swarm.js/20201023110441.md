---
title: Instaswarm
---

Instaswarm is an instagram clone on Swarm.

In this instance we take the approach of using federated aggegators, since it is unlikely that any one client will be able to process all feeds from all over the swarm and maintain the fluidity and speed of user experience.

Aggregator nodes are responsible for providing indexed and denormalised collation of a subset of disparate data stored in the swarm.

Each Instaswarm user may choose the aggregators of their choosing based on reputation.

Our aggregators will be managed by a simple contract on the blockchain (see sig for other thoughts on this). This aggregation contract enables a simple subset of functionality. It is clear however, that many other features such as payment for agreggation services, reporting, banning, reputation management, staking, collaborative or inputs to algorithmic election of feeds to publicly viewable global feeds besides much more could be achieved using this approach. For now, to keep things simple, we will assume our aggregators are free, beautiful and honest.

Each user will then be responsible for storing their own user data in a series of documents satisfying the application data protocols, in this case we will use the PouchDB protocol. PouchDB allows for users to create a database in their client, export a subset of contents of this database containing public information, which can then later be easily combined by aggregators running the same software. PouchDB may also be easily inserted into Erlang based CouchDB clusters, which are able to handle the global scale map reduce queries required to denormalise the data into a digest which enables clients to efficiently view data which originated from many different distinct sources. The details of this are obscured below for simplicity.

#### Aggregator Contract

Let's start with our super simple aggregator contract code.

```solidity
pragma solidity >=0.4.22 <0.7.0;

/**
 * @title Aggregate
 * @dev Maintain a list of the Swarm addresses of feeds to be aggregated and their aggregators.
 * @dev Intended as a ludicrously simple example.
 * @dev Many other functionalities begging to be added here.
 */
contract Aggregate {

    address [] public feeds;
    address [] public feedAggregators;

    function register() public {
        feeds.push(msg.sender);
    }
    
    function registerAggregator(address feedAggregatorAddress) public {
        feedAggregators.push(msg.sender);
    }

}
```

As we can see, this is kept to a bare minimum for simplicity. Just two arrays of addresses. Everything else is handled by Swarm, and the application data protocol. Error handling has been omitted for brevity and legibility

#### Generate User Content

```js

let instaAggrContractAddress = "3edf...233e" //death to all 0x it is obviously hex

let salt = "instaSwarmFTW<3<3<3";

let instaUserSwarm = new Swarm(salt, {wallet: {type: 'metamask'}});

let instaSocCollection = new swarmS.soc('publicDataFeed', {type: 'timeseries'});

let instaPouch = new InstaPouch(); //it simply adds data and retrieves data using pouchdb, no Swarm magic in here...

let mediaLocation1 = instaUserSwarm.upload(file1); //file is a browser or node file object

await instaPouch.addPost({
	caption: "Hello Swarm #wearetheswarm",
	mediaLocation: mediaLocation1,
	mediaType: 'mp4',
	timestamp: Date.now()
})

let mediaLocation2 = instaUserSwarm.upload(file2);

await instaPouch.addPost({
	caption: "Hello Again Swarm #wearetheswarm",
	mediaLocation: mediaLocation2,
	mediaType: 'png',
	timestamp: Date.now()
})

let mediaLocation3 = instaUserSwarm.upload(file3);

await instaPouch.updateProfile({
	name: "sigmund1",
    bio: "Hi I'm Sig from Swarm ðŸ‘‹",
	profileImage: mediaLocation3,
})


await instaPouch.follow({
	id: "a6ef3456..."
})

await instaPouch.follow({
	id: "b6ef3456..."
})

await instaPouch.unfollow({
	id: "b6ef3456..."
})

let userDump = instaPouch.dump();

await instaSocCollection.upload(userDump); 

//uploads the json, sets the pointer in the soc feed for the relevant time epoch (default now)

let instaAggrContract = new instaUserSwarm.contract(instaAggrContractAddress, instaAggrContractAbi); //please not web3, let's roll our own we need a tiny subset of the functionality. the benefit of doing this is we are handling the key management implicitly which will make it very easy for uninitiated web devs and this is where we leapfrog everything else so the effort is worth concentrating in the lib

instaAggrContract.register();
```

Because Instaswarm is all about images and videos, we will need to deal with data that is going to be over the maximum capacity of a single chunk, however swarm.js will handle this automatically.

The aggregators produce aggregates of the data, but an individual's feed is different for each individual. In order to have byzantine-tolerant aggregations the aggregations must be checked by multiple parties. This makes this approach expensive. This is the manifestation of Swarm's underlying design and principles. The cost must be borne by the user, so in a sense a clone of Instagram is not a good example of an Dapp on Swarm.

In this example, we will assume that each user compiles their own feed to make things simpler. 

#### Aggregate, Denormalise Data and Create Cached Feeds and Indexes

```js
let salt = "instaSwarmFTW<3<3<3";

let aggrUserSwarm = new Swarm(salt, {wallet: {type: 'localstore'}});

let instaPouch = new InstaPouch(); //it's a fictional pouch adapter but this is eminently achievable

let instaAggrContract = new aggrUserSwarm.contract(instaAggrContractAddress, instaAggrContractAbi);

let feedOwners = instaAggrContract.feeds();

feedOwners.each((owner)=>{
    let soc = new aggrUserSwarm.SOC('publicDataFeed', {type: 'timeseries', owner});
    try{
        let socFeed = soc.latest();
    }catch(e){
        if(e.status.code !== 404){
            throw new Error(e);
        }
    }
    instaPouch.import(socFeed);
});

//create denormalised views of the data
let indexOfFeeds = instaPouch.denormalise();

//create search indexes which will work locally with something like lunr.js
//this enables a byzantine tolerant approach
instaPouch.createSearchIndexes();

//upload all the indexes and denormalised data
let references = await instaPouch.upload();

//analyse each post for hashtags
//when one is found 
    //add this to the cached list of hashtags, 
        //dump it as paginated json documents
        //maintain a SOC timeseries feed with the latest version of each page
        //add these to the global index
    //create a new cached aggregation of the feed, dump it as a pouchdb view
        //dump it as paginated json documents
        //maintain a SOC timeseries feed with the latest version
        //add these to the global index
    //dump the global index
        //maintain a SOC timeseries feed with the latest version

let soc = new aggrUserSwarm.SOC('instaIndex', {type: 'timeseries'});
soc.upload(references);
```

#### Consume Aggregated Feeds and Indexes

```js
//fetch main index soc
//load search index
//search for a hashtag using the search index and find a swarm reference
//retrieve the data at the reference
//the data has a pointer to the next page
//and so on...
```