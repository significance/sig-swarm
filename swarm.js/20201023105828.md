---
title: Swarm.js
---

### Abstract

Swarm.js is a medium level library which brings together all the functionality needed to work with primitives at the Dapp level in Swarm. It does not seek to provide application level primitives such as standardised profiles or user accounts, instead to provide a way of working with the new primitives created by Swarm and Eth compatible blockchains.

It assumed, as in Bee, that for now Swarm.js will work with one swarm network and one blockchain per instance. The blockchain part is necessary to be able to manage BZZ balance and pay cheques, and is further useful when dealing with elements of blockchain that for now are best achieved using smart contracts on a blockchain. As we will see later in the examples, it is possible to design creative schemes using Swarm primitives such as Single Owner Chunks that obviate the need for expensive state entries on a global blockchain.

[tbc] It is focused on providing web developers with the ability to interact with Bee golang nodes providing gateway functionality over http and websockets. *

[tbc] It is focused on providing web developers with the ability to interact with Bee golang nodes functionality over TCP and Websockets *

Swarm.js seeks to provide out of the box ability to interact with the basic building blocks of the Swarm network, creating and retrieving the various types of chunks. However, Swarm.js allows users to specify many different options for each layer. The intention is to be deceptively simple and simulltaneously nuanced and powerful. To allow very fine granularity of control, while also ensuring the uninitiated users a beautifully elegant and frictionless onboarding experience.

* see transport below for a detailed discussion of this.

### Conceptual Separation of Concepts

Classes are rigourously unit tested and isolated absolutely in the low layer, and as much as is possible in the median layer - so that they may later be easily restructured as standalone packages, for now everything is included in one monolithic package to reduce friction in development.

High is out of scope but included it aid in identification of functionality inteded to be provided by external packages.

##### Low

- create primitives
- join and split
- datatype manipulation
- sign data
- transactions

##### Median

- with transport
- encryption
- collections
- blockchain
- forwarding

##### High

- accounts
- ORM
- collaborative datasets
- storage node

### Design Goals


	- lightweight
	- devs only required to understand swarm primitives
	- never any cryptolitter 
		- 0x stripped on way in and not required


### Scope

	- build apps in browser
	- build apps in node
	- use in node cli

	- expose simple api of swarm primitives
	- encryption of chunk content

	- not a full node
	- not application level code

### Testing and CI

Unit and integration testing should be completed in both major versions of node and all of the major browser environments.

### Transport

The question of how to deal with transport protocols in the browser is a particularly tricky one.

To address it, let's break everything down to basic principles. Some of this you may already know.

- At the hardware level, a computer has a networking chipset that sends and receives data as a stream of binary bytes.
*Wifi card or cellular phone router.*

- At the software kernel level, traffic is differentiated by network ports, each of which can receive and send data.
*LInux, MacOS, Windows, Android, ...*

- In userspace software programs can listen for or send data to other IP addresses over the internet.
*Golang, C, Node.js, Python, Ruby, ...*

- Because this is an insecure design, firewalls have been introduced that can open or block certain ports.
*Software firewalls, Hardware Firewalls*
- Network Address Translation is commonly used to circumvent ipv4 address exhaustion.
    - Ports may be forwarded across the NAT
    - If enabled, UPNP can automatically forward ports across a NAT.
*Hardware Router*

- At the browser sandbox level, data may be *requested* from any IP and Port combination. 
- It is not possible to *listen* for incoming connections.
- The individual *protocols* are limited to only TCP outgoing*
- To circumvent this, Web Sockets may be used to keep a long running outgoing TCP connection.
- * Other protocols have been added to web browsers to help bridge the gap.
    - WebRTC allows bi-directional communication over audio, video and data channels.
        - STUN
        - TURN
- There are some other exotic protocols that may have patchy support.


So that was a lot of information, but the crux of it is, in general *the browser must initiate all connections*. 

Now, let's have a look at some categories of Swarm's network traffic.

#### Protocols

Push Sync
*Once a chunk has been accepted, the network will ensure it reaches it's closest node by continuously passing it to closer nodes until it has reached it's final destination, on reaching this destination, a statement of custody receipt is sent back via the same route* 

Pull Sync
*An actor requests a chunk from it's nearest peer, that peer then forwards the request until it is found or there is no closer peer. If it is found, the chunk is passed back to the originator of the request, if it is not found a 404 error is passed back.*

#### Functionality

Discovery
*Nodes are requested and share about information regarding their peers* 
*It is possible for discovery to work with only outgoing connections, as long as there are enough nodes that are answering incoming discovery requests.*

Upload Chunk
*Data is input from another piece of software, processed into network acceptable chunks and accepted into the network* 
*Uploading data into the network only requires outgoing connection to one or more nodes*

Download Chunk
*Data is output from the client to another piece of software.* 
*Downloading data into the network only requires outgoing connection to one or more nodes*

Forwarding
*Forwarding traffic is generated using both push and pull sync* 
*Forwarding traffic can only be acheived if it is possible to answer incoming connections*

Storage
*Storage nodes retain chunks with addresses in their neighbourhood and respond to pull sync requests as the source of the data*
*Storage nodes must be able to answer incoming connections*

Trojan Chunks
*Trojan chunks are content address chunks which are encrypted in such a way that they may only be decrypted or even detected by someone with the corresponding key material *
*Storage nodes must be able to answer incoming connections*

#### Running Libp2p in Node and the Browser

Libp2p has pluggable transports and has the capability to be run on Websockets, TCP, WebRTC, QUIC, UDP and UTP.

Although WebRTC is known to be faster and more efficitient (citation needed), support in Golang is currently listed as Unstable.

The other protocols are similarly unsupported or unimplementable.

Because of this, Websockets is our only choice to be able to connect to Golang Bee nodes using the javascript implementation of Libp2p.

source: https://libp2p.io/implementations/

#### Connecting Over Libp2p is No Silver Bullet

What advantages does connecting over Libp2p give us?

The most significant advantage is the ability to consume already existing protocol services which are being satisfied by the Bee nodes making up the network. These services form a superset of what is currently available from the API.

However, this is no silver bullet. Each of these services will need a reimagined endpoint to satisfy the different end user requirements created by the nature of the environments that our javascript code will likely be run in. It may also be necessary to engineer a different set of data adapters to interact with protobuf interfaces vs. api endpoints.

#### Javascript User Environment Targets

##### Node.js

Node.js is a javascript runtime that runs javscript just like it were any other script running in userspace. This is a fundamentally different environment to that of a browser. The Node.js environment benefits from all of the same privileges as any other software running natively on a computer such as access to incoming and outgoing network ports, unabated access to the filesystem, and so on. It also has completely different API's such as the *Buffer* object which is a more sane way approach to native javascript's *ArrayBuffer* and associated types. Some familiar objects from the browser are totally missing, of course there is no *window* or other DOM elements, but futhermore the *File* and *Localstorage* api's are missing. This list is by no means exhaustive!

##### Browser

Web browsers run a *sandboxed* runtime which is *mostly* isolated for each tab or iframe.

Browsers have a *very limited* set of functionality designed to improve security for web users. Javascript running in a browser is prevented from accessing the computer's file system and networking ports.

Despite, or perhaps because of this, browsers do have a rich and diverse set of API's that node does not. WebRTC provides p2p wire protocols via STUN and TURN protocols. File objects can be created using input html entities, and so on...

Because browsers do not have access to block filestorage, it is not possible to use the environment to directly store large amounts of data in a reliable or sane manner. The browser sandbox environment does typically have access to some limited storage space and storing data in using browser Localstorage, IndexDB, volatile memory and (?) is possible to a various extents depending on the environment the browser is run in. However, lack of access to the native file system makes it impractical to administrate long term storage nodes.

In many environments bandwidth may also be limited, and this would make the nodes purely consumers and remuniration of the gateways would be necessitated by other means. Similarly, some environments may have very limited computational power or RAM and this should be considered when benchmarking the software.

However, in many cases this is not true, and increasingly less so will it be.

In these cases it is possible and preferable to provide the ability to forward chunks:
    - Earn BZZ / Self Sustaining
    - Detect Trojan Chunks

Requesting, looping through all blocks and checking them for signs of Trojans in a neighbourhood may well take quite some computation and bandwidth, inversely proportional to the amount of time spent mining the chunk.

##### Browser Plugins

Browser plugins have an additional set of functionalities which allow priveleged access to the computer filesystem (and other ?) from the browser environment.

#### Desired Behavior for Javascript Execution Environments

Basically what's missing from the api, how long does it take us to add this in and create adapters in js that can run it vs how long will it take to get the protobuf and libp2p working and how feasible is it to allow these to connect to arbitary bee nodes? Additionally, how much can we modularise this so it can be repurposed to allow us to transfer to the other method after, finally what's missing from the protocols that is in the gateway api. the gateway api is useful for anything that doesn't  have libp2p eg. python etc.

### swarm primitives

	- trc
	- soc
	- tro
	- bea

### wallet & signing

    - many accounts at once?

	- memory
	- localhost?
	- metamask
	- pluggable

	- get balance
	- send balance

### pinning

	- automatic
	- granular control based on 
		- TTL
		- redundancy
	- repinning
	- for SOC's (and other content) pin only latest version

### api and design

	- initially simple
	- powerful and detailed granular control
	- extensible
	- typescript with well defined types
	- rigorous unit testing
	- integration testing
	- dual testing in node and browser environments


### API

#### Swarm

- address salt for mnemonic or whatever

```js
	let swarm = new Swarm({
		transport: "http", //ws, webrtc
		bootnode: "https://gateway.ethswarm.org", //gateway node, or a trusted bootnode which will bootstrap discovery
        minPeers: 5,
		wallet: "metamask",
		network_id: 1, //mainnet
		salt: 0, //optional, defines data planar environment, adds obsfuction, or 0 for public
		mode: 'light',
		pin: 'all',
        blockchain: {
            endpoint: "https://infura.io...",
            networkID: 1
        }
	})
```

### Transport

#### HTTP
#### WS
#### WebRTC

### Bootnode

* https://gateway.ethswarm.org (default)
* specify any multiaddress

can be multiple

(nb should be bee addresses have bee or bzz in them to implicate protocol?)

### Wallet

Swarm runs on BZZ. This is the gas that powers the Swarm network. Small amounts of gas are exchanged between peers in return for services such as retrieving chunks, or paying peers in the network to retain blocks that are not in your neighbourhood. In return, you will receive payment for serving chunks in your neighbourhood to other peers.

Because you must have BZZ you must have a wallet containing BZZ (and ETH) in order to pay for and receive payment for services you receive or consume.

There are 3 varieties of wallet provided, but this is pluggable and there is also [an ecosystem](tbc) of other ways to sign transactions.

memory
localstorage
metamask

swarm.js allows the use of a waterfall system of passwords that means you only need to sign very important transactions manually.

### Network ID

Network ID is already know.

### Salt

Salt may be a new concept to some, but it is well known in cryptographic circles. This can be conceptualised as defining a subspace within a set of numbers. Imagine all of the numbers as a solid three dimensional cube. If you take a two dimensional cross section through the box, you define a flat square with a subset of the total amount of single dimensional points in that cube. This is analogous to providing a salt.

The usefulness of this is in that we are able to indicate a defined space in the universe of the swarm's total address space. This enables us not only to provide a clear space for our application where we can be sure of no collisions with other application's chunks, but also a map to be able to find each other's data in the bewildering vastness of the swarm. See [SIANA]() for more details

### Mode

neighbourhood depth, bandwidth allocation, storage allocation, forwarding only....

#### Worker Bee

Swarm.js can perform the task of forwarding chunks in the network. In many instances, where bandwidth is unmetered and energy is available, it is often a good idea to help the swarm network deliver it's chunks, in return for fun and profit! Moving these chunks around the network often covers

:::info
	Check out bumblebee.js for the implementation of a full node in javascript including cold storage. swarm.js is a lightweight library concerned with browser and embedded device integration. For effective storage, we must have access to the file system and due to browser sandboxing this is not permitted. if you prefer a UI, the bumblebee browser plugin or native electron app enables access to the your computers filesystem and allows you to administrate your storage node.
:::

For the most part, may want to forward messages, for a full mining client that runs with js, see Bumblebee.js

#### Paid

Sometimes there just isn't any bandwidth to be spared. In this eventuality, we must pay for what we use.

#### Loan Worker

Generous souls out there will may lend you some BZZ in return for interest to get you started.

#### Gift

To help onboarding, we might be gifted bzz under certain circumstances. This arrives in the form of prefunded wallets with an ephemeral key which is never secure.

### Pin

transport: "http", //ws, webrtc
bootnode: "", //gateway node, or a trusted bootnode which will bootstrap discovery
wallet: "localstorage", //localstorage mode for the wallet, lowest security, see //wallet
network_id: 1, //mainnet
salt: 0, //optional, defines data planar environment, adds obsfuction, or 0 for public
mode: 'light',
pin: 'all'


#### Single Owner Chunk

- type of feed
- salt
- index hint
- owner

Swarm.js has a key value mode which automatically unpins previous content if history mode is turned off (it is by default). 

		//soc type

		//soc types contain the full index and index type, they can be moved forwards and backwards
		//as soc types ratchet forward and backward we uses encryption schemes to give deterministically known encryption keys to data as well as encrypted pointer locations

		soc.next() //it's a nod to dfeeds
		soc.prev()
		soc.at() //time, index, arbitrary scheme compressed to bytes 32
		soc.new() //only you can create socs you have the id's for
		soc.upload() //but you may upload other peoples socs if you have them
		soc.download() //socs are verified on download
		soc.latest() //attempts to finds the latest in a series
		soc.get() //get the whole history of the soc series
        soc.set() //get the whole history of the soc series

 //single owner chunk collection,
  Uint indexed, 
  salt is 0x0, 
  we are starting at 0 (no previous index to add),
  it is the owners block

Single owner chunks underpin the usefullness of Swarm to Dapp developers. They give users the right to write in a certain subspace of the global DISC, and conversely allow users to find other users content in the DISC if so desired.

constructor


tro

bea



// topic: integer/constant/string
// index: integer/timestamp/
// content: null
// media: json/binary/file

//nb pointers should be 'automatic'
//nb encryption is automatic, specify public if it is public

//SWID:string32:0x51632...
//TOPIC:string32:0x1337
//SALT:random32:
//INDEX:uint32:0
//NOMINATED_SWID:hex32:0x7417...
//NOMINATED_LEGEND:hex32:RPICC


// topic: integer/constant/string
// index: integer/timestamp/
// content: null
// media: json/binary/file

//nb pointers should be 'automatic'
//nb encryption is automatic, specify public if it is public

		//INITIALISE WOF

		let topic = '1337';


		let soc = new swarm.SOC(topic, {
			mimeType, //json/binary/file
			encryption, //normalEncryption/public/others, define interface to allow pluggable
			timeToLive, //seconds, date/time string specific formats eg. 1w
			pinnedPriority, 
			indexType, //uint, traditional feeds, many others i am sure, define interface to allow pluggable
			salt, //sometimes you might want to add dimesions here
			user, //in the default case we are creating it using the key generation scheme, but sometimes we'll need to specify the user's address
			prefix //prefix - in the default case we are happy with any prefix, for beacon blocks or sae's we may want to place the block in a specific neighbourhood 
		}, /*user*/)

		//let's educate the public about salt. it is nicely familiar, everyone loves salt

		//soc type

		//soc types contain the full index and index type, they can be moved forwards and backwards
		//as soc types ratchet forward and backward we uses encryption schemes to give deterministically known encryption keys to data as well as encrypted pointer locations

		soc.next() //it's a nod to dfeeds
		soc.prev()
		soc.at() //time, index, arbitrary scheme compressed to bytes 32
		soc.new() //only you can create socs you have the id's for
		soc.upload() //but you may upload other peoples socs if you have them
		soc.download() //socs are verified on download
		soc.latest() //attempts to finds the latest in a series
		soc.get() //get the whole history of the soc series

		soc.upload({
			genesis: true,
			nominated_swid: "0x51632...",
			nominated_legend: "RPICC"
		}) //default make a json, first one is index 0

		//loads of options to customise here too
		//salt
		//encryption
		//pinned etc.

		let GENESIS_CHUNK_REFERENCE = soc.reference();
		let GENESIS_CHUNK_OWNER_ADDRESS = swarm.address(); //default is address[0], many addresses available through deterministic wallets
		let GENESIS_CHUNK_PAYLOAD_HASH = keccack256(soc.payload());

